{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from constants import LABEL_COLUMN, TEXT_COLUMN, TRAINING_DATA_PATH, EMBEDDING_SIZE, ALPHABET_COLUMN, ALPHABETS, SMALL_ALPHABETS, TINY_ALPHABETS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train_data_with_embedding_per_column.csv\")\n",
    "\n",
    "# Replace label NaN with the string \"nan\" (the string \"nan\" is interpreted as a NaN value by pandas)\n",
    "df[\"Label\"].replace(to_replace=np.nan, value=\"nan\", inplace=True)\n",
    "\n",
    "# Remove label with only 1 occurence\n",
    "df = df.groupby(\"Label\").filter(lambda x: len(x) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 38850 entries, 0 to 38853\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      38850 non-null  int64 \n",
      " 1   Label   38850 non-null  object\n",
      " 2   Text    38850 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"ID\", \"Label\", \"Text\"]].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_alphabet(text):\n",
    "    detected = \"\"\n",
    "    \n",
    "    for char in text:\n",
    "        char_code = ord(char)\n",
    "        \n",
    "        for alphabet, (start, end) in ALPHABETS.items():\n",
    "            if start <= char_code <= end:\n",
    "                detected = alphabet\n",
    "    \n",
    "    return detected if detected else \"Inconnu\"\n",
    "\n",
    "df[ALPHABET_COLUMN] = df[TEXT_COLUMN].apply(detect_alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Roberta only: 0.8367531294360563\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"data/train_predictions.csv\")\n",
    "\n",
    "# Train data\n",
    "X_train = data[data[\"Type\"] == \"Train\"]\n",
    "X_train = pd.merge(X_train, df, on=['Text', 'ID', 'Usage', 'Label'], how=\"inner\")\n",
    "X_train[\"Label\"].replace(to_replace=np.nan, value=\"nan\", inplace=True)\n",
    "# Roberta predictions\n",
    "predictions_roberta = pd.read_csv(\"data/train_predictions.csv\")\n",
    "\n",
    "# Test predictions\n",
    "#X_test = pd.merge(pd.DataFrame(test_texts, columns=[\"Text\"]), predictions_roberta, on=[\"Text\"], how=\"inner\")\n",
    "X_test = data[data[\"Type\"] == \"Test\"]\n",
    "X_test = pd.merge(X_test, df, on=['Text', 'ID', 'Usage', 'Label'], how=\"inner\")\n",
    "X_test[\"Label\"].replace(to_replace=np.nan, value=\"nan\", inplace=True)\n",
    "X_test[\"PredictedLabel\"].replace(to_replace=np.nan, value=\"nan\", inplace=True)\n",
    "X_test.rename(columns={\"PredictedLabel\": \"Prediction\"}, inplace=True)\n",
    "\n",
    "# Accuracy with Roberta only\n",
    "print(\"Accuracy with Roberta only:\", (X_test[\"Label\"] == X_test[\"Prediction\"]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training for alphabet with up to 5 different languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_classifiers = {}\n",
    "\n",
    "for small_alphabet in SMALL_ALPHABETS:\n",
    "\n",
    "    X_train_small = X_train[X_train[ALPHABET_COLUMN] == small_alphabet]\n",
    "    X_test_small = X_test[X_test[ALPHABET_COLUMN] == small_alphabet]\n",
    "\n",
    "    classifier = RandomForestClassifier()\n",
    "    classifier.fit(X_train_small[[f\"embedding_{i}\" for i in range(EMBEDDING_SIZE)]], X_train_small[LABEL_COLUMN])\n",
    "    \n",
    "    small_classifiers[small_alphabet] = classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Tiny: 0.9864864864864865\n",
      "Accuracy Small: 0.8991596638655462\n",
      "Accuracy Large: 0.8331127580730545\n",
      "Total accuracy: 0.8355916892502259\n",
      "f1-score: 0.8350256693723388\n"
     ]
    }
   ],
   "source": [
    "# Alphabet with only one language\n",
    "preds_tiny_alphabets = {}\n",
    "weights_tiny_alphabets = {}\n",
    "tiny_alphabet_matching = { \"Thai\":\"tha\", \"Hiragana\": \"jpn\", \"Gujarati\":\"guj\", \"Korean\": \"kor\",\"Katakana\": \"jpn\" }\n",
    "for tiny_alphabet in TINY_ALPHABETS:\n",
    "    preds_tiny_alphabet = X_test[X_test[ALPHABET_COLUMN] == tiny_alphabet]\n",
    "    preds_tiny_alphabet[\"Prediction\"] = tiny_alphabet_matching[tiny_alphabet]\n",
    "    preds_tiny_alphabets[tiny_alphabet] = preds_tiny_alphabet\n",
    "    weights_tiny_alphabets[tiny_alphabet] = len(preds_tiny_alphabet)\n",
    " \n",
    "accuracy_tiny = 0\n",
    "for key in preds_tiny_alphabets:\n",
    "    accuracy_tiny += (preds_tiny_alphabets[key][\"Label\"] == preds_tiny_alphabets[key][\"Prediction\"]).sum()\n",
    "print(\"Accuracy Tiny:\", accuracy_tiny / sum(weights_tiny_alphabets.values()))\n",
    "\n",
    "\n",
    "# Alphabet with up to 5 different languages\n",
    "preds_small_alphabets = {}\n",
    "weights_small_alphabets = {}\n",
    "for small_alphabet in SMALL_ALPHABETS:\n",
    "    classifier = small_classifiers[small_alphabet]\n",
    "    preds_small_alphabet = X_test[X_test[ALPHABET_COLUMN] == small_alphabet]\n",
    "    preds_small_alphabet[\"Prediction\"] = classifier.predict(preds_small_alphabet[[f\"embedding_{i}\" for i in range(EMBEDDING_SIZE)]])\n",
    "    preds_small_alphabets[small_alphabet] = preds_small_alphabet\n",
    "    weights_small_alphabets[small_alphabet] = len(preds_small_alphabet)\n",
    "\n",
    "accuracy_small = 0\n",
    "for key in preds_small_alphabets:\n",
    "    accuracy_small += (preds_small_alphabets[key][\"Label\"] == preds_small_alphabets[key][\"Prediction\"]).sum()\n",
    "    \n",
    "print(\"Accuracy Small:\", accuracy_small / sum(weights_small_alphabets.values()))\n",
    "\n",
    "# Alphabet with more than 5 different languages\n",
    "large_alphabets = ALPHABETS.keys() - set(SMALL_ALPHABETS + TINY_ALPHABETS)\n",
    "large_alphabets.add(\"Inconnu\")\n",
    "\n",
    "preds_large_alphabets = {}\n",
    "weights_large_alphabets = {}\n",
    "for alphabet in large_alphabets:\n",
    "    preds_large_alphabet = X_test[X_test[ALPHABET_COLUMN] == alphabet]\n",
    "    preds_large_alphabets[alphabet] = preds_large_alphabet\n",
    "    weights_large_alphabets[alphabet] = len(preds_large_alphabet)\n",
    "\n",
    "accuracy_large = 0\n",
    "for key in preds_large_alphabets:\n",
    "    accuracy_large += (preds_large_alphabets[key][\"Label\"] == preds_large_alphabets[key][\"Prediction\"]).sum()\n",
    "print(\"Accuracy Large:\", accuracy_large / sum(weights_large_alphabets.values()))\n",
    "\n",
    "# Accuracy and f1-score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "preds = pd.concat([preds_tiny_alphabets[key] for key in preds_tiny_alphabets] + [preds_small_alphabets[key] for key in preds_small_alphabets] + [preds_large_alphabets[key] for key in preds_large_alphabets])\n",
    "print(\"Total accuracy:\", (preds[\"Label\"] == preds[\"Prediction\"]).mean())\n",
    "print(\"f1-score:\", f1_score(preds[\"Label\"], preds[\"Prediction\"], average=\"weighted\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
